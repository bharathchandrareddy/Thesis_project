{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of model performance on in-domain-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models\n",
    "from torchvision.models import ResNet34_Weights\n",
    "from legacy.zoo.models import *\n",
    "from datasets.base_dataset import LabeledDataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pytorch_toolbelt.utils import fs\n",
    "\n",
    "from xview.dataset import get_test_dataset, OUTPUT_MASK_KEY\n",
    "from xview.inference import (\n",
    "    Ensembler,\n",
    "    model_from_checkpoint,\n",
    "    run_inference_on_dataset,\n",
    "    ApplySoftmaxTo,\n",
    "    MultiscaleTTA,\n",
    "    HFlipTTA,\n",
    "    D4TTA,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "models_checkpoints = [\"path/to/model1.pth\", \"path/to/model2.pth\"]  # Add your model paths here\n",
    "output_dir = \"path/to/output\"\n",
    "fast = False\n",
    "tta = None\n",
    "batch_size = 1\n",
    "workers = 0\n",
    "data_dir = \"data\"\n",
    "postprocessing = \"dominant\"\n",
    "image_size = (1024, 1024)\n",
    "activation_after = \"model\"\n",
    "fp16 = False\n",
    "align = False\n",
    "weights = None  # Example: [0.1, 0.2, 0.3, 0.2, 0.2] if using weights\n",
    "\n",
    "# Check weights validity\n",
    "assert weights is None or len(weights) == 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Res34_Unet_Double(pretrained = False)\n",
    "checkpoint = torch.load(model_path)\n",
    "#our model keys and saved checkpoint keys are mismatched, so we need to correct them\n",
    "new_state_dict = {}\n",
    "for key,value in checkpoint['state_dict'].items():\n",
    "    new_key = key.replace('model.','')\n",
    "    new_state_dict[new_key]=value\n",
    "model.load_state_dict(new_state_dict)\n",
    "missing_keys, unexpected_keys = model.load_state_dict(new_state_dict,strict=False)\n",
    "print(f'missing_keys = {missing_keys}')\n",
    "print(f'unexpected_keys = {unexpected_keys}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "infos = []\n",
    "\n",
    "for model_checkpoint in models_checkpoints:\n",
    "    try:\n",
    "        model, info = model_from_checkpoint(\n",
    "            fs.auto_file(model_checkpoint), tta=None, activation_after=activation_after, report=False\n",
    "        )\n",
    "        models.append(model)\n",
    "        infos.append(info)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Error with model checkpoint: {model_checkpoint}\")\n",
    "        break  # Exit the loop if loading fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(infos)\n",
    "print(df)\n",
    "\n",
    "print(\"Score:\", df[\"score\"].mean(), df[\"score\"].std())\n",
    "print(\"Localization:\", df[\"localization\"].mean(), df[\"localization\"].std())\n",
    "print(\"Damage:\", df[\"damage\"].mean(), df[\"damage\"].std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to process datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%b%d_%H_%M\")\n",
    "\n",
    "if output_dir is None and len(models_checkpoints) == 1:\n",
    "    output_dir = os.path.join(\n",
    "        os.path.dirname(models_checkpoints[0]),\n",
    "        fs.id_from_fname(models_checkpoints[0]) + \"_test_predictions\",\n",
    "    )\n",
    "    if weights is not None:\n",
    "        output_dir += \"_weighted\"\n",
    "    if tta is not None:\n",
    "        output_dir += f\"_{tta}\"\n",
    "else:\n",
    "    output_dir = output_dir or f\"output_dir_{current_time}\"\n",
    "\n",
    "print(\"Size:\", image_size)\n",
    "print(\"Output dir:\", output_dir)\n",
    "print(\"Postprocessing:\", postprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from typing import Dict, Union, Any, List\n",
    "\n",
    "def normalize_image(img: torch.Tensor) -> torch.Tensor:\n",
    "    img = img.to(torch.float32)\n",
    "    img /= 127\n",
    "    img -= 1\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_images(images_folder: str, masks_folder: str) -> List[Dict[str, Union[torch.Tensor, Any]]]:\n",
    "    results = []\n",
    "\n",
    "    for image_filename in os.listdir(images_folder):\n",
    "        if '_pre_' not in image_filename:\n",
    "            continue\n",
    "\n",
    "        # Construct full paths for pre-disaster and post-disaster images\n",
    "        img_pre_path = os.path.join(images_folder, image_filename)\n",
    "        img_post_path = img_pre_path.replace('_pre_', '_post_')\n",
    "\n",
    "        # Construct full paths for pre-disaster and post-disaster masks\n",
    "        msk_pre_path = os.path.join(masks_folder, image_filename)\n",
    "        msk_post_path = msk_pre_path.replace('_pre_disaster', '_post_disaster')\n",
    "\n",
    "        # Print paths for debugging\n",
    "        # print(f\"Processing image: {image_filename}\")\n",
    "        # print(f\"img_pre_path: {img_pre_path}\")\n",
    "        # print(f\"img_post_path: {img_post_path}\")\n",
    "        # print(f\"msk_pre_path: {msk_pre_path}\")\n",
    "        # print(f\"msk_post_path: {msk_post_path}\")\n",
    "\n",
    "        # Read images\n",
    "        img_pre = cv2.imread(img_pre_path, cv2.IMREAD_COLOR)\n",
    "        img_post = cv2.imread(img_post_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Read masks\n",
    "        msk_pre = cv2.imread(msk_pre_path, cv2.IMREAD_UNCHANGED)\n",
    "        msk_post = cv2.imread(msk_post_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        if img_pre is None or img_post is None or msk_pre is None or msk_post is None:\n",
    "            print(f\"Skipping file: {image_filename}, missing images or masks.\")\n",
    "            continue\n",
    "\n",
    "        # Ensure masks are integer type\n",
    "        msk_pre = msk_pre.astype(np.uint8)\n",
    "        msk_post = msk_post.astype(np.uint8)\n",
    "\n",
    "        # Print unique values in masks\n",
    "        # print(f\"Unique values in msk_pre: {np.unique(msk_pre)}\")\n",
    "        # print(f\"Unique values in msk_post: {np.unique(msk_post)}\")\n",
    "\n",
    "        # Create separate masks for different disaster levels\n",
    "        msk0 = (msk_pre > 0).astype(np.uint8)[..., np.newaxis]\n",
    "        msk1 = (msk_post == 1).astype(np.uint8)[..., np.newaxis]\n",
    "        msk2 = (msk_post == 2).astype(np.uint8)[..., np.newaxis]\n",
    "        msk3 = (msk_post == 3).astype(np.uint8)[..., np.newaxis]\n",
    "        msk4 = (msk_post == 4).astype(np.uint8)[..., np.newaxis]\n",
    "\n",
    "        # Combine masks\n",
    "        msk = np.concatenate([msk0, msk1, msk2, msk3, msk4], axis=2)\n",
    "\n",
    "        # Concatenate pre and post-disaster images\n",
    "        img = np.concatenate([img_pre, img_post], axis=2)\n",
    "\n",
    "        # Convert to tensors\n",
    "        img_tensor = torch.from_numpy(img.transpose((2, 0, 1))).float()\n",
    "        msk_tensor = torch.from_numpy(msk.transpose((2, 0, 1))).float()\n",
    "\n",
    "        # Normalize the image tensor\n",
    "        img_tensor = normalize_image(img_tensor)\n",
    "\n",
    "        # Add the processed image and mask tensors to the result list\n",
    "        results.append({'img': img_tensor, 'msk': msk_tensor,'fn':image_filename})\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset,batch_size=8, shuffle=False, num_workers=6):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        shuffle=shuffle,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import torchmetrics.classification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, test_loader, threshold=0.38, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataloader and display confusion matrices.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model to evaluate.\n",
    "        test_loader (torch.utils.data.DataLoader): Dataloader for the test dataset.\n",
    "        threshold (float): Threshold for the location mask.\n",
    "        device (str): Device to use for evaluation ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of F1 scores per channel and displays confusion matrices.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    model.to(device)\n",
    "\n",
    "    num_classes = 2  # Assuming binary classification\n",
    "    test_metrics = [torchmetrics.F1Score(num_classes=num_classes, task='binary', average='none').to(device) for _ in range(5)]  # Assuming 5 channels\n",
    "    #confusion_matrices = [torchmetrics.ConfusionMatrix(num_classes=num_classes,task='multiclass').to(device) for _ in range(5)]  # Confusion matrices for 5 channels\n",
    "    # Reset metrics\n",
    "    for metric in test_metrics :\n",
    "        metric.reset()\n",
    "    results = {}\n",
    "\n",
    "    with torch.no_grad():  # No need for gradient computation during evaluation\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            x, y = batch[\"img\"].float().to(device), batch[\"msk\"].float().to(device)\n",
    "            y_hat = model(x).float()  # Forward pass\n",
    "            \n",
    "\n",
    "            # Apply sigmoid activation\n",
    "            y_sigm = torch.sigmoid(y_hat)\n",
    "\n",
    "            # Location prediction mask\n",
    "            # to distuinguish between building presence or absense\n",
    "            loc_pred = y_sigm[:, 0, ...]\n",
    "            loc_msk = (loc_pred > threshold)  # Binary mask based on threshold\n",
    "\n",
    "            # Damage mask: 5-class prediction per pixel\n",
    "            dmg_msk = y_sigm[:, 1:, ...].argmax(axis=1) + 1\n",
    "            dmg_msk = dmg_msk * loc_msk  # Combine location and damage masks\n",
    "\n",
    "            # One-hot encode the damage mask\n",
    "            hot_dmg_msk = torch.zeros_like(y_hat, dtype=y_hat.dtype)\n",
    "            for i in range(5):\n",
    "                hot_dmg_msk[:, i, ...] = (dmg_msk == i)\n",
    "            hot_dmg_msk[:, 0, ...] = loc_msk  # Update location channel\n",
    "            \n",
    "            # Update metrics for each channel\n",
    "            for i in range(y_hat.shape[1]):\n",
    "                test_metrics[i].update(hot_dmg_msk[:, i, ...], y[:, i, ...])\n",
    "                preds = hot_dmg_msk[:, i, ...].flatten()\n",
    "                targets = y[:, i, ...].flatten()\n",
    "                \n",
    "                # Print unique values\n",
    "                # print(f\"Batch {batch_idx}, Channel {i}\")\n",
    "                # print(f\"Unique values in predictions: {torch.unique(preds)}\")\n",
    "                # print(f\"Unique values in targets: {torch.unique(targets)}\")\n",
    "                #confusion_matrices[i].update(hot_dmg_msk[:, i, ...], y[:, i, ...])\n",
    "            # if batch_idx == 2:  # Limit to first 3 batches\n",
    "            #     break\n",
    "\n",
    "    #Compute the final F1 scores and display confusion matrices for each channel\n",
    "    for i in range(len(test_metrics)):\n",
    "        results[f\"test_channel_{i}_F1\"] = test_metrics[i].compute().item()\n",
    "\n",
    "    #     # Plot confusion matrix\n",
    "    #     cm = confusion_matrices[i].compute().cpu().numpy()\n",
    "    #     plt.figure(figsize=(6, 6))\n",
    "    #     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "    #                 xticklabels=[f'Class_{j}' for j in range(num_classes)], \n",
    "    #                 yticklabels=[f'Class_{j}' for j in range(num_classes)])\n",
    "    #     plt.title(f\"Confusion Matrix for Channel {i}\")\n",
    "    #     plt.xlabel(\"Predicted\")\n",
    "    #     plt.ylabel(\"Actual\")\n",
    "    #     plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "model_dir = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\prediction_masks\\\\no_aug\"\n",
    "\n",
    "# Define a color mapping for the damage mask (5 classes: 0-4)\n",
    "damage_color_map = {\n",
    "    0: [0, 0, 0],       # Class 0 (background) - black\n",
    "    1: [0, 255, 0],     # Class 1 (minor damage) - green\n",
    "    2: [255, 255, 0],   # Class 2 (moderate damage) - yellow\n",
    "    3: [255, 165, 0],   # Class 3 (major damage) - orange\n",
    "    4: [255, 0, 0],     # Class 4 (destroyed) - red\n",
    "}\n",
    "\n",
    "# Define a color mapping for the localization mask (binary: 0 and 1)\n",
    "localization_color_map = {\n",
    "    0: [0, 0, 0],       # Not localized - black\n",
    "    1: [0, 255, 0],     # Localized - green\n",
    "}\n",
    "\n",
    "def mask_to_color(mask, color_map):\n",
    "    \"\"\"Convert a single-channel mask to a 3-channel color image.\"\"\"\n",
    "    height, width = mask.shape\n",
    "    color_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    for class_id, color in color_map.items():\n",
    "        color_img[mask == class_id] = color\n",
    "        \n",
    "    return color_img\n",
    "\n",
    "def pred_one_image(pred, threshold=0.38):\n",
    "    \"\"\"\n",
    "    Processes the model's prediction for a single image, creating localization and damage masks.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): The model's raw output for a single image.\n",
    "        threshold (float): Threshold for binary localization mask.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (loc_msk, dmg_msk)\n",
    "            loc_msk: Localization mask (binary).\n",
    "            dmg_msk: Damage mask (multi-class).\n",
    "    \"\"\"\n",
    "    y_sigm = torch.sigmoid(pred)  # Apply sigmoid activation to the prediction\n",
    "    y_pred = y_sigm.cpu().numpy().transpose(1, 2, 0)  # Convert to numpy and move channel to last position\n",
    "    \n",
    "    loc_pred = y_pred[..., 0]  # Get the localization prediction (first channel)\n",
    "    loc_msk = (loc_pred > threshold).astype('uint8')  # Apply threshold to create binary localization mask\n",
    "    \n",
    "    dmg_msk = y_pred[..., 1:].argmax(axis=2) + 1  # Get the damage class (argmax over the remaining channels)\n",
    "    dmg_msk = dmg_msk * loc_msk  # Mask the damage predictions using the localization mask (only where loc_msk == 1)\n",
    "    \n",
    "    loc_msk = loc_msk.astype('uint8')\n",
    "    dmg_msk = dmg_msk.astype('uint8')\n",
    "    # After generating the damage mask, check the unique values\n",
    "    print(\"Unique values in the damage mask:\", np.unique(dmg_msk))\n",
    "\n",
    "    \n",
    "    return loc_msk, dmg_msk\n",
    "\n",
    "def save_colored_predictions(loc_msk, dmg_msk, file_name):\n",
    "    # Convert localization and damage masks to color images\n",
    "    loc_color = mask_to_color(loc_msk, localization_color_map)\n",
    "    dmg_color = mask_to_color(dmg_msk, damage_color_map)\n",
    "    \n",
    "    # Save the colored images\n",
    "    loc_filename = file_name.replace('_pre_disaster', '_localization_disaster_prediction_colored')\n",
    "    dmg_filename = file_name.replace('_pre_disaster', '_damage_disaster_prediction_colored')\n",
    "    \n",
    "    cv2.imwrite(os.path.join(model_dir, loc_filename), loc_color)\n",
    "    cv2.imwrite(os.path.join(model_dir, dmg_filename), dmg_color)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_step(model, test_loader, device='cuda', threshold=0.38):\n",
    "    \"\"\"\n",
    "    Predicts and saves output masks (localization and damage) for all batches in the DataLoader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model to use for prediction.\n",
    "        test_loader (torch.utils.data.DataLoader): Dataloader for the test dataset.\n",
    "        device (str): The device to run the model on ('cuda' or 'cpu').\n",
    "        threshold (float): Threshold for localization mask.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    model.to(device)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(test_loader):  # Loop over batches from the test_loader\n",
    "        x, fns = batch[\"img\"].float().to(device), batch[\"fn\"]  # Get the input images and filenames\n",
    "        \n",
    "        y_hat = model(x).float()  # Forward pass through the model\n",
    "        \n",
    "        for pred, fn in zip(y_hat.unbind(dim=0), fns):\n",
    "            file_name = fn.split('/')[-1]  # Extract file name from full path\n",
    "            \n",
    "            # Process the prediction (apply sigmoid, threshold, and generate masks)\n",
    "            loc_msk, msk_dmg = pred_one_image(pred, threshold=threshold)\n",
    "            \n",
    "            # Save the colored localization and damage masks\n",
    "            save_colored_predictions(loc_msk, msk_dmg, file_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting an image and generating masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Guatemala\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Guatemala_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "test_results = predict_step(model, dataloader, device='cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysing competition split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\test\\\\images\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\test\\\\masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# After loading processed_data\n",
    "for i in range(3):  # Visualize first 3 samples\n",
    "    sample = processed_data[i]\n",
    "    img = sample['img'].numpy().transpose(1, 2, 0)  # Shape: (H, W, 6)\n",
    "    msk = sample['msk'].numpy().transpose(1, 2, 0)  # Shape: (H, W, C)\n",
    "\n",
    "    # Separate pre- and post-disaster images\n",
    "    pre_img = img[:, :, :3]   # First 3 channels\n",
    "    post_img = img[:, :, 3:]  # Last 3 channels\n",
    "\n",
    "    # De-normalize images for display\n",
    "    pre_img_display = (pre_img + 1) * 127.5 / 255\n",
    "    post_img_display = (post_img + 1) * 127.5 / 255\n",
    "\n",
    "    # Display the images and masks\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Display pre-disaster image\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(pre_img_display)\n",
    "    plt.title('Pre-Disaster Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display post-disaster image\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(post_img_display)\n",
    "    plt.title('Post-Disaster Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display the first mask channel (e.g., building presence)\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(msk[..., 0], cmap='gray')\n",
    "    plt.title('Mask Channel 0')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display the second mask channel (e.g., damage level 1)\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(msk[..., 1], cmap='gray')\n",
    "    plt.title('Mask Channel 1')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "test_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in test_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of arkansas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Arkansas\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Arkansas_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "california_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in california_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\California\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\California_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "california_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in california_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of mexico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Mexico\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Mexico_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "mexico_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in mexico_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Florida\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Florida_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "florida_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in florida_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of hawai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Hawaii\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Hawaii_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of Missouri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Missouri\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Missouri_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of Nepal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Nepal\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Nepal_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of oklahoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\oklahoma\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\oklahoma_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of portugal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Portugal\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Portugal_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of south australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\South_australia\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\South_australia_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of south carolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\South_Carolina\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\South_Carolina_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "carolina_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in carolina_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Indonesia\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Indonesia_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "indonesia_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in indonesia_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Texas\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Texas_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of locations not seen by the model\n",
    "\n",
    "# 1. alabama\n",
    "# 2. Guatemala\n",
    "# 3. Sunda\n",
    "# 4. ayiti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of alabama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Alabama\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Alabama_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of Guatemala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Guatemala\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Guatemala_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis if sunda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\sunda\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\sunda_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of Ayiti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Ayiti\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\location_test_data\\\\Ayiti_masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "texas_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in texas_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysing out-of-domain dataset (Ida-BD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test data loader\n",
    "images_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\Ida-BD_dataset\\\\images\"\n",
    "masks_folder = \"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\Ida-BD_dataset\\\\masks\"\n",
    "processed_data = process_images(images_folder, masks_folder)\n",
    "dataloader = create_dataset(processed_data)\n",
    "# Assuming `model` is your trained model and `test_loader` is your test DataLoader\n",
    "ida_bd_results = evaluate_model(model, dataloader, device='cuda')\n",
    "\n",
    "# Print the F1 scores for each channel\n",
    "for channel, f1_score in ida_bd_results.items():\n",
    "    print(f\"{channel}: {f1_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
